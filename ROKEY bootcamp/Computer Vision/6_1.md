#컴퓨터비전 
[[컴퓨터 비전]]
last modification: 2024-08-22
![[자료-2-pytorch선형회귀.pdf]]

# Pytorch 선형회귀 예제

###### 토치에서 변수 선언
![[Pasted image 20240822103132.png]]

###### 가중치(w, b)와 gradients 초기화
![[Pasted image 20240822103214.png]]

###### 경사하강법 예제
```python
optimizer = optim.SGD([W, b], lr=0.01)

epochs = 20000

for epoch in range(epochs + 1):
    
    H = x_train * W + b  # 가설 설정
    cost = torch.mean((H - y_train) ** 2)  # 비용함수 선언

	# 기울기를 0으로 초기화한다. 각 에폭을 반복할 때 마다 기울기를 초기화해야 새로운 가중치화 편향에 대한 기울기를 구할 수 있다. 
    optimizer.zero_grad() # 이거 안하면 이전 값이 계속 남아있음
    # 새로운 W, b에 대한 gradient(기울기)를 계산한다
    cost.backward()  # 비용함수 미분해서 gradient 계산
    # 설정한 옵티마이저에 step함수를 이용해서 새로 계산한 기울기에 learning rate를 곱해서 새로운 값으로 업데이트 한 다.
    optimizer.step()  # W, b 업데이트

    if epoch % 100 == 0:
        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(
            epoch, epochs, W.item(), b.item(), cost.item()))
```

###### 자동미분
![[Pasted image 20240822105945.png]]
w에 대해서 알아서 편미분하고 계산

###### 행렬곱 - H(x)
![[Pasted image 20240822110122.png|400]]
![[Pasted image 20240822110151.png]]

###### 쭉 코드 복습

최소제곱법이 수치해석 때 배운거고, 지금 배우는 것은 딥러닝으로 직선을 구하는 것

Hypothesis = 가설

Class
대부분의 경우 클래스를 통해 모델을 만듬
![[Pasted image 20240822111244.png|300]]
연구 쪽으로는 토치를 많이 씀

결국 텐서/토치 양쪽을 알면 좋음.

[Google Colab](https://colab.research.google.com/drive/1AdIPp_V4vGgcMrtzP9kpf6mc-A-Qwahb?hl=ko#scrollTo=jxyR_2eP9n8S)

# 머신러닝
추론보다 분석을 많이 해줌
![[1.Intro_for_AI-0819_-_배포안.pdf]]
p.205

휴대폰 속 AP 구조는 ARM으로 되있음. (저전력이라)

학습할 때 전류가 많이 필요해서 요즘은 arm 씀

###### 머신 러닝을 생각보다 많은 분야를 내포
![[Pasted image 20240822150748.png]]
NLP: Natural Language Processing - 자연어 처리 = 언어를 기계가 이해 할 수 있도록 통역하는 영역. 이 분야가 LLM이랑 요즘 핫함.

지금까지의 딥러닝은 여기저기 들어가는 방법들임.


## 비지도 학습
![[Pasted image 20240822152424.png|400]]

### K-means
(여기는 데분입 참고해도 될 듯)
![[Pasted image 20240822160504.png|300]]
- 군집 중심점(centroid)이라는 특정한 임의의 지점을 선택해 해당 중심에 가장 가까운 포인트들을 선택하는 군집화 기법 
- 선택된 포인트의 평균지점으로 이동하고 이동된 중심점에서 다시 가까운 포인트를 선택, 다시 중심점을 평균 지점으로 이동하는 프로세스를 반복적으로 수행
- 널림 쓰임
단점:
- 반복 작업이 많아지면 매우 느려짐
- 몇개의 군집을 택할지 고르기가 어려움

### Means Shift
![[Pasted image 20240822160441.png|400]]
위랑 다르게 거리가 아닌 밀도로 군집화 계산
영상처리 쪽에 많이 쓰임
사전에 군집의 개수를 정할 필요 없음.
단점:
- 느림

### DBSCAN
![[Pasted image 20240822160600.png|300]]
컨셉만 알고 있으셈
복잡한 기하학적 모양을 가진 곳에 적용 가능

### K-Nearest Neighbor
![[Pasted image 20240822160823.png]]
맨 왼쪽이 k가 1일 때, 우측은 k가 5일 때
![[Pasted image 20240822160854.png]]
정규화가 필요한 방법임. 
###### 중요 정규화 방법:
![[Pasted image 20240822162056.png]]
###### k 개수에 따른 현상
![[Pasted image 20240822162133.png|200]]

### SVM(Support Vector Machine)
분류와 회귀 문제에서 가장 빠른 지도학습 모델
![[Pasted image 20240822162313.png|400]]
이상적인 경계를 찾음
![[Pasted image 20240822163648.png|400]]
잘 모르겠지만 F(우측 아래)가 좋은 듯

마진: 결정경계와서포트벡터사이의거리를의미한다.
![[Pasted image 20240822162630.png|400]]
위에서 검은 테두리가 있는 데이터들이 서포트 벡터
- 최적의결정경계는마진을최대화한다.
- n개의속성을가진데이터에는최소n+1개의 서포트벡터가 존재한다
-  서포트 벡터를 제외한 데이터는 무시하기 때문에 계산이 빠름.

SVC: Support Vector Classifier라고도 함
사용 예시
![[Pasted image 20240822164318.png]]
빨간 점 하나와 파란 점 두개를 서포트 벡터로 이용