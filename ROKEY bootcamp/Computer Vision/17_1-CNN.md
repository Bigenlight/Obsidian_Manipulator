#컴퓨터비전 
[[Ai,컴퓨터 비전]]
last modification: 2024-09-05

# 7장 CNN
[Google Colab](https://colab.research.google.com/drive/1WogPaDJFq9aCdQlyHZVQd4b1v01WLArm#scrollTo=tnl2vESbVP0n) < - 이론 내용 많음
![[05.CNN_intro_20230724.pdf]]

### 이미지 ==커널==
[Image Kernels explained visually](https://setosa.io/ev/image-kernels/)
![[Pasted image 20240905112658.png|500]]
우리가 opencv 때 배우는 이미지 커널(마스크, 필터)
이를 통해 여러 특징을 추출 가능

딥러닝에서는 이 마스크 값을 모델이 스스로 찾음. 우리가 필터 값을 정하는 것이 아님.
그게 CNN.

### CNN 개요
CNN는 FCN과 다르게 바로 연결 되는게 아니라 레이어 사이에 커널을 끼워 넣는 것이다.
그래서 Convolutution Neural Network이다
![[Pasted image 20240905120150.png]]
배치 처리하면 1차원이 증가하긴 함.
기존의 ==FCN을 쓰면 공간 정보를(정보간의 위치 정보, 관계성) 잃어버림==.
==CNN를 통해 이미지의 공간 정보를 유지==하면서 학습이 가능함.

FCN -> 2차원(배치 처리로 1증가) -> 공간 정보 없음
CNN -> ==4차원==(배치 처리로 1 증가) -> 공간 정보 존재

#### CNN 주 용어
![[Pasted image 20240905120628.png|300]]
- 채널 = 가로 x 세로 평면하나 <- 특징을 가짐
- 필터 = 커널 = 이미지를 연산하는 작은 마스크
- 스트라이드 = 이동
- 패딩 =원본 영상과 크기가 같게 유지하기 위해 추가하는 픽셀
- 피처 맵 = 컨볼루션 결과
- 엑티베이션 맵 = 바이서를 더하고 엑비베이션까지 지난 결과
- 풀링 = 이미지를 줄이는 작업

![[Pasted image 20240905122703.png|400]]
하나의 이미지 안에 R, G, B 3개의 채널이 있는겨
각각 하나의 특징을 표현

![[Pasted image 20240905133344.png]]
이렇게 한번 Convolution을 하고
![[Pasted image 20240905134409.png|500]]
이렇게 순환해서 적용 됨. 이때 순환 간격을 ==Stride==라 함.
![[Pasted image 20240905141723.png]]
보통 한칸씩만 움직이는데 stride를 키우면 여러칸 씩 움직임. 그러면 아웃풋이 기하급수적으로 작아짐.

![[Pasted image 20240905134554.png]]
==채널==별로 연산 각각을 하고 마지막에 반드시 서로 합쳐야 됨,
합친 것이 ==피처 맵==.

![[Pasted image 20240905134706.png|400]]
근데 연산을 하고 나면 테두리에 구멍이 생김. 그것을 채우는 것이 ==패딩==.
![[Pasted image 20240905142702.png]]
패딩을 사전에도 채워서 이미지를 유지할 수 있는 듯.
###### 기본적인 Convolution 과정
![[Pasted image 20240905135453.png]]
결과로 두개의 채널을 output으로 가지려면 6개의 필터와 convolution 과정 필요.
위 전체 과정을 Convolution라고도 함.
근데 filter 1, 2도 내부적으로는 다 다른 필터인건가?? 아마 그런 듯. ㅇㅇ 맞는 듯함. 보통 ==채널마다 필요한 가중치가 다르다고==해서.

세분화를 하면
![[Pasted image 20240905135914.png|400]]
채널별로 convolution 계산 -> 다 합침 > 하나의 결과 레이어 탄생 (피처 맵)

보통 개별 convolution 그림과 더하기를 생략함. 잊지말 것.

###### 1 x 1 필터
![[Pasted image 20240905140226.png|500]]
사이즈를(차원) 줄이는 용도. 잃는 정보도 있지만, 연산량을 줄이는데에 의의.

###### 아웃풋 차원 계산 공식
![[Pasted image 20240905135757.png|300]]
(원래 이미지 - filter + padding ) / strider  + 1
![[Pasted image 20240905142837.png|500]]
7x7에 4x4 필터를 패딩은 적용 안한 상태에 strider가 1인 convolution은?
( 7- 4 + 0) / 1  + 1 = 4 -> 4x4 행렬 탄생

![[Pasted image 20240905143301.png]]
만약 6x6x3을 2개 종류의 필터로 패딩 없이 3x3 필터로(f), 1간격으로 스트라이드하면?
( (6+ 0 -3) / 1 ) + 1 = 4 => 일단 4x4
필터가 2종류니 => 4x4x2
총 컨볼루션을 6번 함.

강사님 처럼 ==(가로세로 - 필터가로세로 + 패딩) / 스트라이더 + 1== 방식으로 외우는게 좋을 듯.
##### Coonvolution Layer
![[Pasted image 20240905141312.png]]
최종 아웃풋이 ==Activation map.==  <- 합치고 Relu로 활성함수 통과 한 뒤

![[Pasted image 20240905145558.png]]
 컨볼루션을 각각 30, 200, 800번 함 (이전 마지막이랑, 이후 마지막 수 곱하면 됨 (3x10, 10x20, 20x40))
마지막에 FCN으로 분류. 딥러닝으로 필터 파라미터를 구하는데, 이 때 결과와 출력 된 종속 변수를 비교하여 역전파를 통해 파라미터를 찾음.

##### Pooling Layer
![[Pasted image 20240905150438.png]]
여러개 칸 중에서 최대칸, 또는 평균 칸만 남기고 이미지를 축소키는 것. (가로 세로만)
요즘은 ==최대칸을 남기는 방법을 주로 쓴다고== 함.

연산량을 줄이기 위해 사용하는 직접적인 방법.

![[Pasted image 20240905150810.png]]
사이즈 f가 2면 가로 세로가 각각 2배 줄어듬.

세부적인 디테일이 아니라 큼지막한 특징만 필요할 때 사용.

풀링이 빠지면 작은 특징 밖에 못 봄. 전체적인 큰 특징을 못 본다고 함.

#### 여러 CNN
##### 최조의 CNN LeNet 5 - 일명 르넷, 르네상스 마냥 초기의 CNN
![[Pasted image 20240905151053.png]]
파란색 레이어 -> 노란색 과정이 풀링.
필터 몇 종류가 각각 적용 됐는지는 안적혀 있는데 그냥 다음 레이어 마지막 차원이 필터 종류 개수임. 각각 6개와 16개. 컨볼루션은 36번과 96번 함.

CNN 아웃풋은 ==4차원==이지만 FCN 들가면 ==2차원 됨.==

##### AlexNet
처음으로 ==GPU== 이용.
![[Pasted image 20240905152520.png]]

##### VGG-16
2014년도에 나옴
![[Pasted image 20240905152610.png]]
==3x3 필터==를 엄청 씀
3x3 필터를 두개 쓰면 5x5하나와 같음.
세개면 7x7랑 비슷.
근데 연산량도 유리하고, 성능도 더 좋음.
이전에는 큰 필터를 썼는데, 그 보다는 많이 하는게 좋다고 밝혀짐.
그래서 요즘은 3x3을 많이 씀.

다양한 크기 범위의 특징을 추출할 수 있음.

##### Inception
==google net== 기본
![[Pasted image 20240905152859.png]]
여러개의 필터를 각각 적용하고.
나중에 다 ==합침== (Concatinate로)
그래서 마지막 레이어에서 다양한 특징을 볼 수 있음.

이게 GoogleNet
![[Pasted image 20240905153150.png]]
이때 여기서 1x1필터를 많이 썼는데.
채널을(3번째 차원) 192 -> 96, 16, 32 등으로 대폭 축소시킴.
이를 통해 연산량을 많이 줄임.
마지막에 다 합쳐서 채널이 256개.

![[Pasted image 20240905153957.png]]

근데 이래봐도 ==보통 연산량이 FCN에 몰려==있음. CNN는 연산이 생각보다 빠름. 계산이 진행 될 때마다 점점 연산량이 줄어들기도하고.

###### 프레임워크에 따른 CNN 코드 적용
![[Pasted image 20240905155100.png|500]]
텐서플로우1은 잘 안씀.

#### CNN 코드 적용
[Site Unreachable](https://colab.research.google.com/drive/1-ELITGWN51opFiFxBrjWahPl0t7PhcQ1?usp=drive_open)

![[Pasted image 20240905155625.png]]
파이토치가 위 이용 - 채널 단위 처리
텐서플로우가 아래 이용 - 픽셀 단위 처리 <- 마지막 c가 구글의 알록달락한 G
![[Pasted image 20240905155722.png]]

참고로 nchw는 이거임
![[Pasted image 20240905171231.png|200]]

딥러닝에서는 역전파로 필터에(마스크, 커널) 들어가는 가중치를 알아서 계산함.

### 교재
[Google Colab](https://colab.research.google.com/drive/1WogPaDJFq9aCdQlyHZVQd4b1v01WLArm#scrollTo=tnl2vESbVP0n)
요즘은 CNN가 아니라 Transformer를 많이 쓰긴 씀.
하지만 전통적인 것들은 다 CNN. 욜로 같은거.

CNN 구조
![[Pasted image 20240905165428.png]]

##### IM2 함수
4차원을 6차원르 바꾼 후 2차원으로 바꿈. 이를 통해 행렬을 내적으로 계산. (4-6-2)
이를 통해 연산 속도와 복잡성을 줄임. 
![[Pasted image 20240906143448.png]]
![[Pasted image 20240905171826.png|500]]

##### 층 깊이에 따라 보는 특징이 다름
![[Pasted image 20240905172150.png]]
처음에는 세세한 디테일,
풀링 후 점점 커다란 것을 봄.


CNN 전체 구현 코드가 있누

