#컴퓨터비전 
[[Ai,컴퓨터 비전]]
last modification: 2024-09-09

# 딥러닝, 텐서플로우와 케라스
[Site Unreachable](https://colab.research.google.com/drive/1pIgLQOWayLOrlAF7u1PFFnehL6mC_vdq#scrollTo=B9F_uIlkAGpP)

![[Pasted image 20240909120125.png|300]]
- 가장 널리 쓰이는 딥러닝 프레임워크 중 하나
- 구글이 주도적으로 개발하는 플랫폼
- 파이썬, C++ API를 기본적으로 제공하고, 자바스크립트(JavaScript), 자바(Java), 고(Go), 스위프트(Swift) 등 다양한 프로그래밍 언어를 지원
- tf.keras를 중심으로 고수준 API 통합 (2.x 버전)
- TPU(Tensor Processing Unit) 지원
    - TPU는 GPU보다 전력을 적게 소모, 경제적
    - 일반적으로 32비트(float32)로 수행되는 곱셈 연산을 16비트(float16)로 낮춤

원래 텐서 플로우는 어려웠음
컴파일이라는 개념이 있어서.

그래서 그 위에 Keras을 두고 사용했음.
![[Pasted image 20240909120253.png|400]]
- 파이썬으로 작성된 고수준 신경망 API로 TensorFlow, CNTK, 혹은 Theano와 함께 사용 가능
- 사용자 친화성, 모듈성, 확장성을 통해 빠르고 간편한 프로토타이핑 가능
- 컨볼루션 신경망, 순환 신경망, 그리고 둘의 조합까지 모두 지원
- CPU와 GPU에서 매끄럽게 실행

하지만 텐서플로우가 Keras를 흡수하면서 통합 됨.

#### Tensor
데이터의 기본 구조를 tensor로 표현.
![[Pasted image 20240909120424.png]]
==차원수를 Rank==라 함

그동안 numpy를 이용하여 텐서를 사용했음.
이제는 tensorflow 텐서를 이용 할 것.
```python
import numpy as np
import tensorflow as tf
```
기본 구조는 같지만 기능이 더 많음.

t0라는 텐서에 1 집어넣기
```python
t0 = tf.constant(1)
```
print(t0)하면
tf.Tensor(1, shape=(), dtype=int32)
이렇게 나옴.

랭크를 출력하라고 하면
print(tf.rank(t0))
tf.Tensor(0, shape=(), dtype=int32)
앞부분이 차원수로 출력 됨.

2차원 텐서
![[Pasted image 20240909122340.png|300]]

###### 4차원은 주로 컬러 이미지에 쓰임.
 주로 샘플(samples), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조
![[Pasted image 20240909122458.png|300]]

###### 5차원은 주로 비디오
 주로 샘플(samples), 프레임(frames), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조로 사용.
#### Tensor 자료형
- 텐서의 기본 dtype
    - 정수형 텐서: `int32`
    - 실수형 텐서: `float32`
    - 문자열 텐서: `string`
    - 필요시 `float16`, `int8`도 이용

정수
i = tf.constant(2)
tf.Tensor(2, shape=(), dtype=int32)

실수
f = tf.constant(2.)
tf.Tensor(2.0, shape=(), dtype=float32)

문자열
s = tf.constant('park')
tf.Tensor(b'park', shape=(), dtype=string)

###### 추가 자료형 정의
실수 16비트
f16 = tf.constant(2.,dtype=tf.float16)
정수 8비트
i8 = tf.constant(2,dtype=tf.int8)
###### 자료형 변환
tf.cast(바꾸고 싶은 텐서, 자료형)
f32 = tf.cast( f16, tf.float32 )

==참가로 '8' 같이 스트링 속 숫자는 이걸로 한번에 변화 안됨.==
넘파이 한번 거치고 가야 계산 가능.
s2 = tf.constant('2')
i32 = tf.constant(int(s2.numpy()), dtype=tf.int32)
#### 텐서 연산
###### +, - 가능
![[Pasted image 20240909142013.png|350]]
기호, 함수 둘다 있음.

==다만 정수와 실수는 계산 안됨==, 자동 변환 안되누
수동으로 변화하고 계산해야.

## 딥러닝 구조 및 학습
- 딥러닝 구조와 학습에 필요한 요소
    - 모델(네트워크)를 구성하는 **레이어(layer)**
    - **입력 데이터**와 그에 대한 **목적(결과)**
    - 학습시에 사용할 피드백을 정의하는 **손실 함수(loss function)**
    - 학습 진행 방식을 결정하는 **옵티마이저(optimizer)

### 레이어
- Keras에서 사용되는 주요 레이어
    - Dense - Affine, 또는 Affine + Activation 레이어가 여기에 포함
    - Activation - 얘가 Dense 레이어 안에 포함 될 수도 있고, 독립적으로도 표현 가능.
    - Flatten - 보통 4차원을 2차원으로 바꿀 때 이용.
    - Input - 
```python
from tensorflow.keras.layers import Dense, Activation,Flatten,Input
```
#### Dense
- 완전연결계층(Fully-Connected Layer)
- 노드수(유닛수), 활성화 함수(`activation`) 등을 지정
- `name`을 통한 레이어간 구분 가능
- 가중치 초기화(`kernel_initializer`) - Randon, Xavier, He 등

Dense(10,activation='softmax')
여기서 10은 출력 node 수. 입력은 앞에서 이미 결정 됨 (호출 할 때).
Affine -> Softmax 레이어를 만들겠다는 뜻

Dense(10, activation='relu', name = 'Dense Layer')
뒤에 name 각 레이어에 이름을 넣는 것이 좋음.

#### Activation
![[Pasted image 20240909151044.png|500]]
활성화 함수

#### Flatten
Flatten(input_shape=(128,3,2,2))
예를 들면 128x3x2x2은 뒤에 3, 2, 2를 그래도 곱하여 12가 됨.
  (128, 3, 2, 2) -> (128, 12)

#### Input
- 모델의 입력을 정의
- `shape`, `dtype`을 포함
- 하나의 모델은 여러 개의 입력을 가질 수 있음

### 모델
#### Sequential()
가장 쉬운 타입
- 모델이 순차적인 구조로 진행할 때 사용

- Sequential 객체 생성 후,`add()`를 이용한 방법
![[Pasted image 20240909152123.png|500]]
모델 선언 후 각 레이어 지정.
![[Pasted image 20240909152232.png|500]]

입력은 0층이고, 기본적으로 정의할 필요는 없음.
0층은 노드와 퍼셉트론이 존재하지 않는다.

- Sequential 인자에 한번에 추가 방법도 있음
![[Pasted image 20240909152741.png|500]]

plot_model(model) 이 함수로 아래 처럼 그림으로 표현 가능
![[Pasted image 20240909155317.png|100]]

#### 함수형 API
가장 추천 되는 방법
- 모델을 복잡하고, 유연하게 구성 가능
- 다중 입출력을 다룰 수 있음
```python
inputs = Input(shape=(28,28,1))

x = Flatten(input_shape=(28,28,1))(inputs)
x = Dense(300, activation='relu')(x)
x = Dense(100, activation='relu')(x)
x = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=x)
model.summary()
```
inputs이 아래 줄에 들어가고, 그 결과 x가 또 다른 곳에 들어가는 방식으로 작동.
![[Pasted image 20240909155201.png|350]]

Sequential로는 만들 수 없는 신경망 구성 가능.
![[Pasted image 20240909155605.png|400]]
![[Pasted image 20240909155615.png|100]]
여기서는 Concatenate을 이용하여 합침.

#### 서브클래싱
커스터마이징에 최적화된 방법
- Model 클래스를 상속받아 Model이 포함하는 기능을 사용할 수 있음
    - `fit()`, `evaluate()`, `predict()`
    - `save()`, `load()`
- 주로 `call()` 메소드안에서 원하는 계산 가능
    - for, if, 저수준 연산 등
- 권장되는 방법은 아니지만 어떤 모델의 구현 코드를 참고할 때, 해석할 수 있어야함

![[Pasted image 20240909160826.png|500]]
이렇게 상속 받고 모델 정의

이제 모델을 만들었으니. 컴파일을 해야함.

### Compile
Loss 함수와 Optimizer 결정

이미 배운 내용

#### Loss 함수
항등함수 -> MSE
sigmpod -> binary cross entropy
softmax -> cross entropy

원핫 인코딩
![[Pasted image 20240909161828.png|500]]

#### 옵티마이저
학습률(learning rate)
![[Pasted image 20240909162446.png|400]]
![[Pasted image 20240909162458.png|300]]

안장점(Saddle Point)
- 기울기가 0이지만 극값이 되지 않음
- 경사하강법은 안장점에서 벗어나지 못함
- ![[Pasted image 20240909163035.png|400]]

###### 지표(Metrics)
- 모니터링할 지표
- `mae`나 `accuracy` 사용
- 줄여서 `acc`로도 사용 가능
- Keras에서 사용되는 지표 종류: [https://keras.io/ko/metrics/](https://www.google.com/url?q=https%3A%2F%2Fkeras.io%2Fko%2Fmetrics%2F)

### 모델 학습, 평가 및 예측 (fit)
fit()
- `x`: 학습 데이터
- `y`: 학습 데이터 정답 레이블
- `epochs`: 학습 회수
- `batch_size`: 단일 배치에 있는 학습 데이터의 크기
- `validation_data`: 검증을 위한 데이터

`evaluate()`
    - 테스트 데이터를 이용한 평가
`predict()`
    - 임의의 데이터를 사용해 예측

###### 오차역전파
![[Pasted image 20240909164402.png|500]]

## MNIST 딥러닝 Tensorflow 예제

#### 모델 저장과 복원
- `save()`
- `load_model()`
- Sequencial API, 함수형 API에서는 모델의 저장 및 로드가 가능하지만 서브클래싱 방식으로는 할 수 없음
- 서브클래싱 방식은 `save_weights()`와 `load_weights()`를 이용해 모델의 파라미터만 저장 및 로드

모델 저장
model.save('keras_mnist_model.h5')

모델 로드
loaded_model = models.load_model('keras_mnist_model.h5')

모델 사용
pred_ys2 = loaded_model.predict(x_test)
![[Pasted image 20240909170933.png|340]]

### 콜백
- `fit()` 함수의 callbacks 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트를 지정할 수 있음
```python
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, TensorBoard
```

여러 개 사용 가능
- ModelCheckpoint
    - `tf.keras.callbacks.ModelCheckpoint`
    - 정기적으로 모델의 체크포인트를 저장하고, 문제가 발생할 때 복구하는데 사용
    - 최상의 모델만을 저장: `save_best_only=True`
    - ![[Pasted image 20240909171437.png|500]]
- EarlyStopping
    - `tf.keras.callbacks.EarlyStopping`
    - 검증 성능이 한동안 개선되지 않을 경우 학습을 중단할 때 사용
- LearningRateSchduler
    - `tf.keras.callbacks.LearningRateSchduler`
    - 최적화를 하는 동안 학습률(learning_rate)를 동적으로 변경할 때 사용
- TensorBoard
    - `tf.keras.callbacks.TensorBoard`
    - 모델의 경과를 모니터링할 때 사용
    - ![[Pasted image 20240909172159.png|400]]

## 딥러닝 학습 기술

##### 오버/언더 피팅 해결
![[Pasted image 20240909172319.png]]

모델의 크기가 데이터 비해 너무 크면 오버피팅 발생. 크기가 적당해야 함.

###### 과소적합 (Underfitting)
- 학습 데이터를 충분히 학습하지 않아 성능이 매우 안 좋은 경우
- 모델이 지나치게 단순한 경우
해결 방안:
    - 충분한 학습 데이터 수집
    - 보다 더 복잡한 모델 사용
    - 에폭수(epochs)를 늘려 충분히 학습
###### 과대적합 (Overfitting)
- 모델이 학습 데이터에 지나치게 맞추어진 상태
- 새로운 데이터에서는 성능 저하
- 데이터에는 잡음이나 오류가 포함
- 학습 데이터가 매우 적을 경우
- 모델이 지나치게 복잡한 경우
- 학습 횟수가 매우 많을 경우
 해결방안:
    - 다양한 학습 데이터 수집 및 학습
    - 모델 단순화: 파라미터가 적은 모델을 선택하거나, 학습 데이터의 특성 수를 줄임
    - 정규화(Regularization)을 통한 규칙 단순화
    - 적정한 하이퍼 파라미터 찾기
###### 과대적합(overfitting)과 과소적합(underfitting) ==방지 방법==
- 모델의 크기 축소
- 가중치 초기화(Weight Initializer)
- 옵티마이저(Optimizer)
- 배치 정규화(Batch Normalization)
- 규제화(Regularization)
- 드롭아웃(Dropout)
근데 이게 공통 방법인지는 잘 모르겠뉴


## 지금까지 했던거 Tensorflow로 다 적용

